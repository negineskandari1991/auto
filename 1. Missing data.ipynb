{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e4b841",
   "metadata": {},
   "source": [
    "# **data wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the process of converting data from the initial format to a format that may be better for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "await piplite.install(['pandas'])\n",
    "await piplite.install(['matplotlib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21949d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n",
    "#install specific version of libraries used in lab\n",
    "#! mamba install pandas==1.3.3\n",
    "#! mamba install numpy=1.21.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956dc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will download the dataset into your browser \n",
    "from pyodide.http import pyfetch\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1fe81",
   "metadata": {},
   "source": [
    "# **Reading the dataset from the URL and adding the related headers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c8579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7314b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "await download(filename, \"auto.csv\")\n",
    "filename=\"auto.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb76957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, names = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what the data set looks like, we'll use the head() method.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3907b",
   "metadata": {},
   "source": [
    "# **Identify and handle missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2616b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert \"?\" to NaN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# replace \"?\" to NaN\n",
    "df.replace(\"?\", np.nan, inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ded30",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.isnull()\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50929766",
   "metadata": {},
   "source": [
    "# Count missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340eb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")\n",
    "\n",
    "# Deal with missing data:\n",
    "    # Drop data\n",
    "    # a. Drop the whole row\n",
    "    # b. Drop the whole column\n",
    "    # Replace data\n",
    "    # a. Replace it by mean\n",
    "    # b. Replace it by frequency\n",
    "    # c. Replace it based on other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277dce3",
   "metadata": {},
   "source": [
    "# **Calculate the mean value for the columns, and Replace \"NaN\" with mean value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122503d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of normalized-losses:\", avg_norm_loss)\n",
    "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
    "print(\"Average of bore:\", avg_bore)\n",
    "avg_horsepower = df['horsepower'].astype('float').mean(axis=0)\n",
    "print(\"Average horsepower:\", avg_horsepower)\n",
    "avg_peakrpm=df['peak-rpm'].astype('float').mean(axis=0)\n",
    "print(\"Average peak rpm:\", avg_peakrpm)\n",
    "\n",
    "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)\n",
    "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)\n",
    "df['horsepower'].replace(np.nan, avg_horsepower, inplace=True)\n",
    "df['peak-rpm'].replace(np.nan, avg_peakrpm, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba1687",
   "metadata": {},
   "source": [
    "# **Calculate the frequency value for the columns, and Replace \"NaN\" with frequency value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see which values are present in a particular column, we can use the \".value_counts()\" method\n",
    "df['num-of-doors'].value_counts()\n",
    "\n",
    "# four    114\n",
    "# two      89\n",
    "\n",
    "#We can also use the \".idxmax()\" method to calculate the most common type automatically\n",
    "df['num-of-doors'].value_counts().idxmax()\n",
    "\n",
    "# 'four' \n",
    "\n",
    "#replace the missing 'num-of-doors' values by the most frequent \n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd3840",
   "metadata": {},
   "source": [
    "# **Drop rows which inlcude NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply drop whole row with NaN in \"price\" column\n",
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
    "\n",
    "# reset index, because we droped two rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb95ae0",
   "metadata": {},
   "source": [
    "# **Correct data format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.dtype() to check the data type\n",
    "#.astype() to change the data type\n",
    "\n",
    "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
    "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
    "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
    "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710618a2",
   "metadata": {},
   "source": [
    "# **Data Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e801d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization is the process of transforming data into a common format, allowing the researcher to make \n",
    "#the meaningful comparison\n",
    "\n",
    "# Convert mpg to L/100km by mathematical operation (235 divided by mpg)\n",
    "df['city-L/100km'] = 235/df[\"city-mpg\"]\n",
    "\n",
    "# check your transformed data \n",
    "df.head()\n",
    "\n",
    "\n",
    "# transform mpg to L/100km by mathematical operation (235 divided by mpg)\n",
    "df[\"highway-mpg\"] = 235/df[\"highway-mpg\"]\n",
    "\n",
    "# rename column name from \"highway-mpg\" to \"highway-L/100km\"\n",
    "df.rename(columns={'highway-mpg':'highway-L/100km'}, inplace=True)\n",
    "\n",
    "# check your transformed data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477aa140",
   "metadata": {},
   "source": [
    "# **Data Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization is the process of transforming values of several variables into a similar range. Typical normalizations \n",
    "#include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling the \n",
    "#variable so the variable values range from 0 to 1.\n",
    "\n",
    "\n",
    "# replace (original value) by (original value)/(maximum value)\n",
    "df['length'] = df['length']/df['length'].max()\n",
    "df['width'] = df['width']/df['width'].max()\n",
    "\n",
    "# show the scaled columns\n",
    "df[[\"length\",\"width\",\"height\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862cde98",
   "metadata": {},
   "source": [
    "# **Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdf56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis\n",
    "\n",
    "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "plt.pyplot.hist(df[\"horsepower\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)   #4: numbers_generated\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647202b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['Low', 'Medium', 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e936e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
    "df[['horsepower','horsepower-binned']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"horsepower-binned\"].value_counts()\n",
    "\n",
    "# Low       153\n",
    "# Medium     43\n",
    "# High        5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "pyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# draw historgram of attribute \"horsepower\" with bins = 3\n",
    "plt.pyplot.hist(df[\"horsepower\"], bins = 3)\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da729e3a",
   "metadata": {},
   "source": [
    "# **Indicator Variable (or Dummy Variable)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An indicator variable (or dummy variable) is a numerical variable used to label categories. \n",
    "#They are called 'dummies' because the numbers themselves don't have inherent meaning.\n",
    "\n",
    "df.columns\n",
    "dummy_variable_1 = pd.get_dummies(df[\"fuel-type\"])\n",
    "dummy_variable_1.head()\n",
    "\n",
    "# diesel\tgas\n",
    "# 0\t0\t1\n",
    "# 1\t0\t1\n",
    "# 2\t0\t1\n",
    "# 3\t0\t1\n",
    "# 4\t0\t1\n",
    "\n",
    "dummy_variable_1.rename(columns={'gas':'fuel-type-gas', 'diesel':'fuel-type-diesel'}, inplace=True)\n",
    "dummy_variable_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "df = pd.concat([df, dummy_variable_1], axis=1)\n",
    "\n",
    "# drop original column \"fuel-type\" from \"df\"\n",
    "df.drop(\"fuel-type\", axis = 1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ab161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indicator variables of aspiration and assign it to data frame \"dummy_variable_2\"\n",
    "dummy_variable_2 = pd.get_dummies(df['aspiration'])\n",
    "\n",
    "# change column names for clarity\n",
    "dummy_variable_2.rename(columns={'std':'aspiration-std', 'turbo': 'aspiration-turbo'}, inplace=True)\n",
    "\n",
    "# show first 5 instances of data frame \"dummy_variable_1\"\n",
    "dummy_variable_2.head()\n",
    "\n",
    "# merge the new dataframe to the original datafram\n",
    "df = pd.concat([df, dummy_variable_2], axis=1)\n",
    "\n",
    "# drop original column \"aspiration\" from \"df\"\n",
    "df.drop('aspiration', axis = 1, inplace=True)\n",
    "\n",
    "df.to_csv('clean_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
